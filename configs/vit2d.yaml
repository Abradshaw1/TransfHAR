# ViT-MAE needs spectrogram input [3, F, TT]
# Only first 3 sensor channels map to R/G/B; extra channels (e.g. gyro) are dropped.
spectrogram:
  enabled: true
  return_image: true
  log_scale: true

# Objective: "mae" (self-supervised) or "supervised" (classification)
objective:
  type: mae                # mae | supervised
  # MAE-specific (masked_2d for HuggingFace ViTMAE)
  mask_ratio: 0.75
  norm_pix_loss: true

vit:
  warm_start: false
  pretrained_id: facebook/vit-mae-base
  resize_hw: [224, 224]
  patch_size: 16
  num_channels: 3

# Architecture params (match facebook/vit-mae-base HF config exactly)
# Used when warm_start=false; warm_start=true ignores these, but these are currenlty set exactly matching the HF config
encoder:
  hidden_size: 768
  num_hidden_layers: 12
  num_attention_heads: 12
  intermediate_size: 3072
  hidden_act: gelu
  hidden_dropout_prob: 0.0
  attention_probs_dropout_prob: 0.0
  qkv_bias: true
  layer_norm_eps: 1.0e-12
  initializer_range: 0.02
  pooling: mean  # mean | cls (used for probe feature extraction)

decoder:
  hidden_size: 512
  num_hidden_layers: 8
  num_attention_heads: 16
  intermediate_size: 2048

trainer:
  seed: 42
  amp: true
  max_steps: 100000
  grad_clip_norm: 1.0
  grad_accum_steps: 1
  val_every_steps: 500

  optim:
    name: adamw
    lr: 0.001
    weight_decay: 0.0001
    betas: [0.9, 0.95]
    eps: 1.0e-8

  sched:
    name: cosine
    warmup_steps: 100

  early_stopping:
    enabled: true
    monitor: val_loss
    patience: 15


